{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe439e1",
   "metadata": {},
   "source": [
    "# 의사결정나무(Decison Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6096dd",
   "metadata": {},
   "source": [
    "- [의사결정 나무](https://scikit-learn.org/stable/modules/tree.html#)\n",
    "  - 모델의 의사결정 규칙을 **나무형태**로 표현하는 모델\n",
    "  - 분할된 영역에 클래스 데이터가 최대한 많이 존재하도록 각 축으로 영역을 분할하여 생성\n",
    "    - 즉, 불순도 (impurity)가 작은 방향, information gain이 큰 방향으로 분기 (e.g., entropy, gini index, ...)\n",
    "  - [ID3](https://tyami.github.io/machine%20learning/decision-tree-2-ID3/), [C4.5](https://tyami.github.io/machine%20learning/decision-tree-3-c4_5/), [CART](https://tyami.github.io/machine%20learning/decision-tree-4-CART/) 등의 알고리즘이 있으며, 본 강의에서는 의사결정나무를 생성하는 대표적인 알고리즘인 CART(Classification And Regression Tree)를 사용\n",
    "- **장점**\n",
    "  - 모델이 생성한 규칙을 이해하기 쉬우며, 축에 수직으로 분할되어 설명력이 좋다.\n",
    "  - 연속형 및 범주형 변수를 모두 처리 할 수 있음.\n",
    "  - 통계적 가정 불필요\n",
    "- **단점**\n",
    "  - 과적합이 발생하기 쉬우므로 가지치기나 앙상블 기법 도입 필요함.\n",
    "  - 입력변수와 출력변수 간의 복잡한 관계에는 사용하기 어려움.\n",
    "  - 분리의 경계점 근방에서는 예측 오류가 클 가능성이 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6452b",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b822863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib\n",
    "#한글꺠짐 방지\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c20fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/class_balance.csv\",encoding=\"EUC-KR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59f8f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X466</th>\n",
       "      <th>X467</th>\n",
       "      <th>X468</th>\n",
       "      <th>X469</th>\n",
       "      <th>X470</th>\n",
       "      <th>X471</th>\n",
       "      <th>X472</th>\n",
       "      <th>X473</th>\n",
       "      <th>X474</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.530189</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>0.359864</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>0.322190</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.274876</td>\n",
       "      <td>0.210238</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.341478</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.469654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.447466</td>\n",
       "      <td>0.189233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523785</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.210356</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.439175</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360781</td>\n",
       "      <td>0.369653</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>0.528684</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.516722</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.376835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460910</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.561615</td>\n",
       "      <td>0.415328</td>\n",
       "      <td>0.313214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263068</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.638747</td>\n",
       "      <td>0.660074</td>\n",
       "      <td>0.520392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110711</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.608414</td>\n",
       "      <td>0.212062</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.360022</td>\n",
       "      <td>0.396033</td>\n",
       "      <td>0.382803</td>\n",
       "      <td>0.070771</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>0.920884</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.337454</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>0.147860</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.508628</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>0.192378</td>\n",
       "      <td>0.061866</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.481919</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.407911</td>\n",
       "      <td>0.336052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132582</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.275930</td>\n",
       "      <td>0.364365</td>\n",
       "      <td>0.302236</td>\n",
       "      <td>0.376615</td>\n",
       "      <td>0.485135</td>\n",
       "      <td>0.627270</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.420272</td>\n",
       "      <td>0.367047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.586806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.343042</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.143012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.785179</td>\n",
       "      <td>0.271804</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.229526</td>\n",
       "      <td>0.244320</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.875565</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.337684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221768</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.024317</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>0.398833</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.164343</td>\n",
       "      <td>0.571191</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.401357</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.592648</td>\n",
       "      <td>0.498146</td>\n",
       "      <td>0.340946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.309061</td>\n",
       "      <td>0.178988</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.179953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0    0.457896  0.530189  0.276976  0.359864  0.193059  0.322190  0.706897   \n",
       "1    0.607100  0.341478  0.518992  0.395300  0.042071  0.469654  0.750000   \n",
       "2    0.360781  0.369653  0.341039  0.021697  0.181737  0.528684  0.491379   \n",
       "3    0.460910  0.413500  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "4    0.263068  0.279821  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "249  0.360022  0.396033  0.382803  0.070771  0.143308  0.920884  0.586207   \n",
       "250  0.508628  0.437628  0.192378  0.061866  0.168425  0.481919  0.715517   \n",
       "251  0.275930  0.364365  0.302236  0.376615  0.485135  0.627270  0.594828   \n",
       "252  0.785179  0.271804  0.400189  0.457851  0.229526  0.244320  0.396552   \n",
       "253  0.164343  0.571191  0.324472  0.401357  0.249864  0.229873  0.448276   \n",
       "\n",
       "           X8        X9       X10  ...      X466      X467      X468  \\\n",
       "0    0.553781  0.653894  0.375204  ...  0.246376  0.711806  0.008532   \n",
       "1    0.542031  0.447466  0.189233  ...  0.523785  0.760417  0.030930   \n",
       "2    0.516722  0.300371  0.376835  ...  0.185769  0.659722  0.005333   \n",
       "3    0.561615  0.415328  0.313214  ...  0.246376  0.000000  1.000000   \n",
       "4    0.638747  0.660074  0.520392  ...  0.110711  0.517361  0.023677   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "249  0.636336  0.337454  0.432300  ...  0.000000  0.597222  0.016212   \n",
       "250  0.270563  0.407911  0.336052  ...  0.132582  0.975694  0.017065   \n",
       "251  0.435673  0.420272  0.367047  ...  0.246376  0.586806  0.008532   \n",
       "252  0.875565  0.110012  0.337684  ...  0.221768  0.767361  0.024317   \n",
       "253  0.592648  0.498146  0.340946  ...  0.214622  0.621528  0.020904   \n",
       "\n",
       "         X469      X470      X471      X472      X473      X474  Y  \n",
       "0    0.013672  0.008467  0.402240  0.238811  0.274876  0.210238 -1  \n",
       "1    0.033203  0.029759  0.210356  0.309339  0.328358  0.439175 -1  \n",
       "2    0.003906  0.005311  0.381877  0.208171  0.208955  0.155761 -1  \n",
       "3    1.000000  1.000000  0.381877  0.208171  0.208955  0.155761 -1  \n",
       "4    0.022461  0.023447  0.608414  0.212062  0.268657  0.092827 -1  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "249  0.013672  0.015997  0.045307  0.147860  0.171642  0.000000  1  \n",
       "250  0.015625  0.016114  0.543689  0.227626  0.320896  0.111165  1  \n",
       "251  0.015625  0.008613  0.343042  0.151751  0.164179  0.143012  1  \n",
       "252  0.019531  0.023461  0.509709  0.398833  0.440299  0.185945  1  \n",
       "253  0.018555  0.020352  0.309061  0.178988  0.201493  0.179953  1  \n",
       "\n",
       "[254 rows x 475 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aca0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,Y 분할\n",
    "Y=data[\"Y\"].copy()\n",
    "X=data.drop(\"Y\",axis=1)\n",
    "X.head(3)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=22,shuffle =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fab58",
   "metadata": {},
   "source": [
    "[[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)]  \n",
    "**sklearn.model_selection.train_test_split**\n",
    "- **test_size** : float or int, default = 0.25, 정수값일시 test사이즈로 설정하고 싶은 샘플 수 입력\n",
    "- **train_size** : float or int, default = None\n",
    "- **random_state** : int, default = None, 랜덤 seed값 설정, 같은 seed 내에선 동일결과 추출 \n",
    "- **shuffle** : bool, default = True, 데이터셋 무작위 추출, 시계열 데이터와 같이 순차적 추출이 필요한 경우엔 Shuffle = False!\n",
    "- **stratify** : array-like, default = None, True일시 계층적 샘플링 진행 ([참고](https://www.investopedia.com/terms/stratified_random_sampling.asp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a71bc",
   "metadata": {},
   "source": [
    "### 2. 평가 지표 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc48e5",
   "metadata": {},
   "source": [
    "![Confusion Matrix](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)\n",
    "\n",
    "###### 이미지 출처 : https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3227a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 출력 함수\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_all_reg(Y_test,pred):\n",
    "    # Specificity를 구하기 위해 confusion matrix를 이용\n",
    "    cm1 = confusion_matrix(Y_test,pred)\n",
    "    specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1]) # TN/(TN + FP), 정상데이터 중 모델이 정상으로 옳게 분류한 비율\n",
    "    \n",
    "    #결과 검사\n",
    "    #recall = cm1[1,1]/(cm1[1,1]+cm1[1,0]) # TP/(TP + FN), 불량데이터 중 모델이 불량으로 옳게 분류한 데이터 비율\n",
    "    #pre = cm1[1,1]/(cm1[1,1]+cm1[0,1]) # TP/(TP + FP), 모델이 불량으로 분류한 데이터 중 실제 불량데이터 비율\n",
    "\n",
    "    G_mean = recall_score(Y_test,pred) * specificity1\n",
    "    \n",
    "    print(\"model의 recall 값은 {:.3f}\".format(recall_score(Y_test,pred)))\n",
    "    print(\"model의 2종 오류 확률 값은 {:.3f}\".format(1-recall_score(Y_test,pred)))\n",
    "    print(\"model의 Specificity 값은 {:.3f}\".format(specificity1))\n",
    "    print(\"model의 1종 오류 확률 값은 {:.3f}\".format(1-specificity1))\n",
    "    print(\"model의 precision 값은 {:.3f}\".format(precision_score(Y_test,pred)))\n",
    "    print(\"model의 f1_score 값은 {:.3f}\".format(f1_score(Y_test,pred)))\n",
    "    print(\"model의 G-mean 값은 {:.3f}\".format(np.sqrt(G_mean)))\n",
    "    print(\"model의 accuracy 값은 {:.3f}\".format(accuracy_score(Y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ec9ce",
   "metadata": {},
   "source": [
    "### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b9042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X465</th>\n",
       "      <th>X466</th>\n",
       "      <th>X467</th>\n",
       "      <th>X468</th>\n",
       "      <th>X469</th>\n",
       "      <th>X470</th>\n",
       "      <th>X471</th>\n",
       "      <th>X472</th>\n",
       "      <th>X473</th>\n",
       "      <th>X474</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.322290</td>\n",
       "      <td>0.413022</td>\n",
       "      <td>0.569323</td>\n",
       "      <td>0.212561</td>\n",
       "      <td>0.161114</td>\n",
       "      <td>0.400306</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>0.800542</td>\n",
       "      <td>0.446230</td>\n",
       "      <td>0.535073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038468</td>\n",
       "      <td>0.538194</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.271282</td>\n",
       "      <td>0.403363</td>\n",
       "      <td>0.196032</td>\n",
       "      <td>0.375072</td>\n",
       "      <td>0.099246</td>\n",
       "      <td>0.725267</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.260319</td>\n",
       "      <td>0.487021</td>\n",
       "      <td>0.458401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.559028</td>\n",
       "      <td>0.022824</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.338521</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.137327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.164343</td>\n",
       "      <td>0.571191</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.401357</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.592648</td>\n",
       "      <td>0.498146</td>\n",
       "      <td>0.340946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.309061</td>\n",
       "      <td>0.178988</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.179953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.334484</td>\n",
       "      <td>0.353618</td>\n",
       "      <td>0.430362</td>\n",
       "      <td>0.546260</td>\n",
       "      <td>0.434019</td>\n",
       "      <td>0.313601</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.573667</td>\n",
       "      <td>0.509271</td>\n",
       "      <td>0.412724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.018208</td>\n",
       "      <td>0.271845</td>\n",
       "      <td>0.153696</td>\n",
       "      <td>0.141791</td>\n",
       "      <td>0.190806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.480214</td>\n",
       "      <td>0.498559</td>\n",
       "      <td>0.204031</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.103541</td>\n",
       "      <td>0.508834</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.813498</td>\n",
       "      <td>0.559951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.503236</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.242047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.352476</td>\n",
       "      <td>0.401779</td>\n",
       "      <td>0.463937</td>\n",
       "      <td>0.126285</td>\n",
       "      <td>0.083402</td>\n",
       "      <td>0.491896</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.473938</td>\n",
       "      <td>0.483313</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.428803</td>\n",
       "      <td>0.116732</td>\n",
       "      <td>0.126866</td>\n",
       "      <td>0.093068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.348334</td>\n",
       "      <td>0.738141</td>\n",
       "      <td>0.596598</td>\n",
       "      <td>0.539023</td>\n",
       "      <td>0.067757</td>\n",
       "      <td>0.421749</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.646279</td>\n",
       "      <td>0.618047</td>\n",
       "      <td>0.370310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.204643</td>\n",
       "      <td>0.809028</td>\n",
       "      <td>0.029437</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.028217</td>\n",
       "      <td>0.525890</td>\n",
       "      <td>0.379377</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.171586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.524848</td>\n",
       "      <td>0.999370</td>\n",
       "      <td>0.156724</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.109003</td>\n",
       "      <td>0.537550</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.706538</td>\n",
       "      <td>0.430161</td>\n",
       "      <td>0.484502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.289561</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.020265</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.211974</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.242786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.605444</td>\n",
       "      <td>0.397618</td>\n",
       "      <td>0.234016</td>\n",
       "      <td>0.637354</td>\n",
       "      <td>0.163959</td>\n",
       "      <td>0.338264</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.792106</td>\n",
       "      <td>0.580964</td>\n",
       "      <td>0.383361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>0.349515</td>\n",
       "      <td>0.282101</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.217039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.197750</td>\n",
       "      <td>0.390574</td>\n",
       "      <td>0.222614</td>\n",
       "      <td>0.132807</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>0.430756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463091</td>\n",
       "      <td>0.483313</td>\n",
       "      <td>0.632953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.039676</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.037589</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>0.247082</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.611548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "165  0.322290  0.413022  0.569323  0.212561  0.161114  0.400306  0.232759   \n",
       "212  0.271282  0.403363  0.196032  0.375072  0.099246  0.725267  0.732759   \n",
       "253  0.164343  0.571191  0.324472  0.401357  0.249864  0.229873  0.448276   \n",
       "222  0.334484  0.353618  0.430362  0.546260  0.434019  0.313601  0.568966   \n",
       "75   0.480214  0.498559  0.204031  0.109006  0.103541  0.508834  0.525862   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "100  0.352476  0.401779  0.463937  0.126285  0.083402  0.491896  0.284483   \n",
       "192  0.348334  0.738141  0.596598  0.539023  0.067757  0.421749  0.379310   \n",
       "44   0.524848  0.999370  0.156724  0.019864  0.109003  0.537550  0.525862   \n",
       "132  0.605444  0.397618  0.234016  0.637354  0.163959  0.338264  0.870690   \n",
       "117  0.197750  0.390574  0.222614  0.132807  0.154885  0.430756  0.500000   \n",
       "\n",
       "           X8        X9       X10  ...      X465      X466      X467  \\\n",
       "165  0.800542  0.446230  0.535073  ...  0.000000  0.038468  0.538194   \n",
       "212  0.260319  0.487021  0.458401  ...  0.283280  0.246376  0.559028   \n",
       "253  0.592648  0.498146  0.340946  ...  0.201493  0.214622  0.621528   \n",
       "222  0.573667  0.509271  0.412724  ...  0.283280  0.246376  0.972222   \n",
       "75   0.813498  0.559951  1.000000  ...  0.604478  0.288678  0.704861   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "100  0.473938  0.483313  0.543230  ...  0.283280  0.246376  0.697917   \n",
       "192  0.646279  0.618047  0.370310  ...  0.410448  0.204643  0.809028   \n",
       "44   0.706538  0.430161  0.484502  ...  0.134328  0.289561  0.694444   \n",
       "132  0.792106  0.580964  0.383361  ...  0.283280  0.246376  0.506944   \n",
       "117  0.463091  0.483313  0.632953  ...  0.283280  0.246376  0.902778   \n",
       "\n",
       "         X468      X469      X470      X471      X472      X473      X474  \n",
       "165  0.003413  0.009766  0.003682  0.504854  0.000000  0.000000  0.032254  \n",
       "212  0.022824  0.022461  0.022485  0.592233  0.338521  0.500000  0.137327  \n",
       "253  0.020904  0.018555  0.020352  0.309061  0.178988  0.201493  0.179953  \n",
       "222  0.019198  0.017578  0.018208  0.271845  0.153696  0.141791  0.190806  \n",
       "75   0.012372  0.014648  0.012172  0.503236  0.536965  0.604478  0.242047  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "100  0.024104  0.033203  0.023404  0.428803  0.116732  0.126866  0.093068  \n",
       "192  0.029437  0.029297  0.028217  0.525890  0.379377  0.410448  0.171586  \n",
       "44   0.020265  0.026367  0.019717  0.211974  0.134241  0.134328  0.242786  \n",
       "132  0.013439  0.017578  0.013549  0.349515  0.282101  0.343284  0.217039  \n",
       "117  0.039676  0.034180  0.037589  0.148867  0.247082  0.328358  0.611548  \n",
       "\n",
       "[203 rows x 474 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20b7b",
   "metadata": {},
   "source": [
    "[[DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)]    \n",
    "**사전 가지치기**   \n",
    ": 나무가 완성(Full Tree)되기 전에 특정조건을 만족하는 경우 알고리즘을 중단하는 방법. 하이퍼파라미터로 손쉽게 설정 가능\n",
    "      \n",
    "**주요 하이퍼파라미터**  \n",
    "- **criterion** : 클래스 동질성을 측정하는 지표 설정, CART에서는 지니불순도(Gini Impurity)를 사용함. [{\"gini\", \"entorpy\", \"log_loss\"}, default = \"gini\"]\n",
    "- **max_depth** : 트리의 최대깊이를 설정. 값이 클수록 모델의 복잡도가 올라간다. [int, default = None]\n",
    "- **min_samples_split** : 자식노드를 분할하는데 필요한 최소 샘플의 수 [int or float, default = 2]\n",
    "- **min_samples_leaf** : leaf node에서 필요한 최소 샘풀수이며, 너무 적을 시 과적합 발생\n",
    "- **max_leaf_nodes** : 최대 leaf node 수 제한 [int, default=None]\n",
    "- **max_features** : 각 노드를 분리할 때 사용 할 최대 속성 수 [int, float or {“auto”, “sqrt”, “log2”}, default=None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a34ba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE 0.7428571428571428\n",
      "BEST PARAMS {'max_depth': 6, 'max_leaf_nodes': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# 원하는 파라미터 설정 (파라미터를 추가하려면 위의 함수에도 추가해줘야함.)\n",
    "# 사전 가지치기를 위한 하이퍼 파라미터들\n",
    "params={\n",
    "    \"max_depth\":[4,6,8,10],\n",
    "    \"min_samples_leaf\" : [2, 4, 6],\n",
    "    \"min_samples_split\" : range(2,8,2),\n",
    "    \"max_leaf_nodes\": [5,10,15]\n",
    "}\n",
    "\n",
    "# ParameterGrid 통해서 모든 경우의 수 만들기 \n",
    "params_list = list(ParameterGrid(params)) # 4x3x3x3 = 총 108개의 경우의수를 담은 리스트 반환\n",
    "\n",
    "# Grid search 진행\n",
    "score_list = []\n",
    "for params2 in params_list:\n",
    "    model_use = DecisionTreeClassifier(random_state = 0,max_depth = params2[\"max_depth\"],min_samples_leaf = params2[\"min_samples_leaf\"],\n",
    "                                   min_samples_split = params2[\"min_samples_split\"],max_leaf_nodes = params2[\"max_leaf_nodes\"]\n",
    "                                  )      \n",
    "    model_use.fit(X_train, Y_train)\n",
    "    valid_pred = model_use.predict(X_test)\n",
    "    tem = f1_score(valid_pred,Y_test) # 성능지표 = f1-score 사용\n",
    "    score_list.append(tem)\n",
    "\n",
    "# BEST SCORE 계산\n",
    "best_index= np.argmax(score_list) # 가장 높은 f1-score 갖는 경우를 best case로 설정\n",
    "print(\"BEST SCORE\", score_list[best_index])\n",
    "print(\"BEST PARAMS\", params_list[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c54e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7428571428571428\n",
      "Train 데이터 성능\n",
      "model의 recall 값은 0.872\n",
      "model의 2종 오류 확률 값은 0.128\n",
      "model의 Specificity 값은 0.983\n",
      "model의 1종 오류 확률 값은 0.017\n",
      "model의 precision 값은 0.974\n",
      "model의 f1_score 값은 0.920\n",
      "model의 G-mean 값은 0.926\n",
      "model의 accuracy 값은 0.936\n",
      " \n",
      "TEST 데이터 성능\n",
      "model의 recall 값은 0.722\n",
      "model의 2종 오류 확률 값은 0.278\n",
      "model의 Specificity 값은 0.879\n",
      "model의 1종 오류 확률 값은 0.121\n",
      "model의 precision 값은 0.765\n",
      "model의 f1_score 값은 0.743\n",
      "model의 G-mean 값은 0.797\n",
      "model의 accuracy 값은 0.824\n"
     ]
    }
   ],
   "source": [
    "# best case의 하이퍼파라미터로 의사결정나무 학습\n",
    "\n",
    "model_use = DecisionTreeClassifier(random_state = 0,max_depth = params_list[best_index][\"max_depth\"],min_samples_leaf = params_list[best_index][\"min_samples_leaf\"],\n",
    "                                   min_samples_split = params_list[best_index][\"min_samples_split\"],max_leaf_nodes = params_list[best_index][\"max_leaf_nodes\"]\n",
    "                                  )\n",
    "model_use.fit(X_train, Y_train)\n",
    "pred_train = model_use.predict(X_train)\n",
    "pred_test = model_use.predict(X_test)\n",
    "tem = f1_score(Y_test,pred_test)\n",
    "print(tem)\n",
    "\n",
    "#출력\n",
    "print(\"Train 데이터 성능\")\n",
    "print_all_reg(Y_train,pred_train)\n",
    "print(\" \")\n",
    "print(\"TEST 데이터 성능\")\n",
    "print_all_reg(Y_test,pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be13af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e81d91ba51e1bf9900dd7d036cbe3d31d033e3ae1051184964e8f8743fed6bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
