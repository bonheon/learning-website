{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01baeb9f",
   "metadata": {},
   "source": [
    "# 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ee54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb3a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,mean_absolute_percentage_error\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib\n",
    "\n",
    "#한글꺠짐 방지\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe653cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X465</th>\n",
       "      <th>X466</th>\n",
       "      <th>X467</th>\n",
       "      <th>X468</th>\n",
       "      <th>X469</th>\n",
       "      <th>X470</th>\n",
       "      <th>X471</th>\n",
       "      <th>X472</th>\n",
       "      <th>X473</th>\n",
       "      <th>X474</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.530189</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>0.359864</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>0.322190</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283280</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.274876</td>\n",
       "      <td>0.210238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.341478</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.469654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.447466</td>\n",
       "      <td>0.189233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.523785</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.210356</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.439175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360781</td>\n",
       "      <td>0.369653</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>0.528684</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.516722</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.376835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0  0.457896  0.530189  0.276976  0.359864  0.193059  0.322190  0.706897   \n",
       "1  0.607100  0.341478  0.518992  0.395300  0.042071  0.469654  0.750000   \n",
       "2  0.360781  0.369653  0.341039  0.021697  0.181737  0.528684  0.491379   \n",
       "\n",
       "         X8        X9       X10  ...      X465      X466      X467      X468  \\\n",
       "0  0.553781  0.653894  0.375204  ...  0.283280  0.246376  0.711806  0.008532   \n",
       "1  0.542031  0.447466  0.189233  ...  0.328358  0.523785  0.760417  0.030930   \n",
       "2  0.516722  0.300371  0.376835  ...  0.208955  0.185769  0.659722  0.005333   \n",
       "\n",
       "       X469      X470      X471      X472      X473      X474  \n",
       "0  0.013672  0.008467  0.402240  0.238811  0.274876  0.210238  \n",
       "1  0.033203  0.029759  0.210356  0.309339  0.328358  0.439175  \n",
       "2  0.003906  0.005311  0.381877  0.208171  0.208955  0.155761  \n",
       "\n",
       "[3 rows x 474 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"./data/class_balance.csv\",encoding=\"EUC-KR\")\n",
    "data['Y'] = data['Y'].map(lambda x: 0 if x == -1 else 1)\n",
    "#X,Y 분할\n",
    "Y=data[\"Y\"].copy()\n",
    "X=data.drop(\"Y\",axis=1)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1542c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X466</th>\n",
       "      <th>X467</th>\n",
       "      <th>X468</th>\n",
       "      <th>X469</th>\n",
       "      <th>X470</th>\n",
       "      <th>X471</th>\n",
       "      <th>X472</th>\n",
       "      <th>X473</th>\n",
       "      <th>X474</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.530189</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>0.359864</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>0.322190</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.274876</td>\n",
       "      <td>0.210238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.341478</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.469654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.447466</td>\n",
       "      <td>0.189233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523785</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.210356</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.439175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360781</td>\n",
       "      <td>0.369653</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>0.528684</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.516722</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.376835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460910</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.561615</td>\n",
       "      <td>0.415328</td>\n",
       "      <td>0.313214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263068</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.638747</td>\n",
       "      <td>0.660074</td>\n",
       "      <td>0.520392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110711</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.608414</td>\n",
       "      <td>0.212062</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.360022</td>\n",
       "      <td>0.396033</td>\n",
       "      <td>0.382803</td>\n",
       "      <td>0.070771</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>0.920884</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.337454</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>0.147860</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.508628</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>0.192378</td>\n",
       "      <td>0.061866</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.481919</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.407911</td>\n",
       "      <td>0.336052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132582</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.275930</td>\n",
       "      <td>0.364365</td>\n",
       "      <td>0.302236</td>\n",
       "      <td>0.376615</td>\n",
       "      <td>0.485135</td>\n",
       "      <td>0.627270</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.420272</td>\n",
       "      <td>0.367047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.586806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.343042</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.143012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.785179</td>\n",
       "      <td>0.271804</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.229526</td>\n",
       "      <td>0.244320</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.875565</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.337684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221768</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.024317</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>0.398833</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.164343</td>\n",
       "      <td>0.571191</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.401357</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.592648</td>\n",
       "      <td>0.498146</td>\n",
       "      <td>0.340946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.309061</td>\n",
       "      <td>0.178988</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.179953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0    0.457896  0.530189  0.276976  0.359864  0.193059  0.322190  0.706897   \n",
       "1    0.607100  0.341478  0.518992  0.395300  0.042071  0.469654  0.750000   \n",
       "2    0.360781  0.369653  0.341039  0.021697  0.181737  0.528684  0.491379   \n",
       "3    0.460910  0.413500  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "4    0.263068  0.279821  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "249  0.360022  0.396033  0.382803  0.070771  0.143308  0.920884  0.586207   \n",
       "250  0.508628  0.437628  0.192378  0.061866  0.168425  0.481919  0.715517   \n",
       "251  0.275930  0.364365  0.302236  0.376615  0.485135  0.627270  0.594828   \n",
       "252  0.785179  0.271804  0.400189  0.457851  0.229526  0.244320  0.396552   \n",
       "253  0.164343  0.571191  0.324472  0.401357  0.249864  0.229873  0.448276   \n",
       "\n",
       "           X8        X9       X10  ...      X466      X467      X468  \\\n",
       "0    0.553781  0.653894  0.375204  ...  0.246376  0.711806  0.008532   \n",
       "1    0.542031  0.447466  0.189233  ...  0.523785  0.760417  0.030930   \n",
       "2    0.516722  0.300371  0.376835  ...  0.185769  0.659722  0.005333   \n",
       "3    0.561615  0.415328  0.313214  ...  0.246376  0.000000  1.000000   \n",
       "4    0.638747  0.660074  0.520392  ...  0.110711  0.517361  0.023677   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "249  0.636336  0.337454  0.432300  ...  0.000000  0.597222  0.016212   \n",
       "250  0.270563  0.407911  0.336052  ...  0.132582  0.975694  0.017065   \n",
       "251  0.435673  0.420272  0.367047  ...  0.246376  0.586806  0.008532   \n",
       "252  0.875565  0.110012  0.337684  ...  0.221768  0.767361  0.024317   \n",
       "253  0.592648  0.498146  0.340946  ...  0.214622  0.621528  0.020904   \n",
       "\n",
       "         X469      X470      X471      X472      X473      X474  Y  \n",
       "0    0.013672  0.008467  0.402240  0.238811  0.274876  0.210238  0  \n",
       "1    0.033203  0.029759  0.210356  0.309339  0.328358  0.439175  0  \n",
       "2    0.003906  0.005311  0.381877  0.208171  0.208955  0.155761  0  \n",
       "3    1.000000  1.000000  0.381877  0.208171  0.208955  0.155761  0  \n",
       "4    0.022461  0.023447  0.608414  0.212062  0.268657  0.092827  0  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "249  0.013672  0.015997  0.045307  0.147860  0.171642  0.000000  1  \n",
       "250  0.015625  0.016114  0.543689  0.227626  0.320896  0.111165  1  \n",
       "251  0.015625  0.008613  0.343042  0.151751  0.164179  0.143012  1  \n",
       "252  0.019531  0.023461  0.509709  0.398833  0.440299  0.185945  1  \n",
       "253  0.018555  0.020352  0.309061  0.178988  0.201493  0.179953  1  \n",
       "\n",
       "[254 rows x 475 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a71bc",
   "metadata": {},
   "source": [
    "# 평가 지표 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb0eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 출력 함수\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_all_reg(Y_test,pred):\n",
    "    # Specificity를 구하기 위해 confusion matrix를 이용\n",
    "    cm1 = confusion_matrix(Y_test,pred)\n",
    "    specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    #결과 검사\n",
    "    #recall = cm1[1,1]/(cm1[1,1]+cm1[1,0])\n",
    "    #pre = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "\n",
    "    G_mean = recall_score(Y_test,pred) * specificity1\n",
    "    \n",
    "    print(\"model의 recall 값은 {:.3f}\".format(recall_score(Y_test,pred)))\n",
    "    print(\"model의 2종 오류 확률 값은 {:.3f}\".format(1-recall_score(Y_test,pred)))\n",
    "    print(\"model의 Specificity 값은 {:.3f}\".format(specificity1))\n",
    "    print(\"model의 1종 오류 확률 값은 {:.3f}\".format(1-specificity1))\n",
    "    print(\"model의 precision 값은 {:.3f}\".format(precision_score(Y_test,pred)))\n",
    "    print(\"model의 f1_score 값은 {:.3f}\".format(f1_score(Y_test,pred)))\n",
    "    print(\"model의 G-mean 값은 {:.3f}\".format(np.sqrt(G_mean)))\n",
    "    print(\"model의 accuracy 값은 {:.3f}\".format(accuracy_score(Y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5fe8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=5,shuffle =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8e7d0",
   "metadata": {},
   "source": [
    "# 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4412be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def evaluate_regression_models(X, y, model_name):\n",
    "    # 데이터 생성    \n",
    "    # 모델 학습\n",
    "    if model_name == \"GBM\":\n",
    "        # Gradient Boosting 모델\n",
    "        X_train, X_eval, y_train, Y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model = GradientBoostingClassifier(max_depth = 8,n_estimators=500,validation_fraction = 0.2, n_iter_no_change = 10,learning_rate = 0.005)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"학습 데이터 성능\")\n",
    "        preds = model.predict(X_train)\n",
    "        print_all_reg(preds,y_train)\n",
    "\n",
    "    elif model_name == \"XGB\":        \n",
    "        # XGBoost 모델\n",
    "        X_train, X_eval, y_train, Y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        eval_set = [(X_eval, Y_eval)]\n",
    "        model = xgb.XGBClassifier(n_estimators=200,learning_rate = 0.005,\n",
    "                        min_child_weight = 2,\n",
    "                        colsample_bytree = 0.7,\n",
    "                        max_depth = 8)\n",
    "        model.fit(X_train, y_train,eval_set = eval_set,early_stopping_rounds = 10)\n",
    "        \n",
    "        print(\"학습 데이터 성능\")\n",
    "        preds = model.predict(X_train)\n",
    "        print_all_reg(preds,y_train)\n",
    "    \n",
    "    elif model_name == \"Light\":     \n",
    "        params = {'learning_rate': 0.01, \n",
    "          'max_depth': 16, \n",
    "          'boosting': 'gbdt', \n",
    "          'metric': 'accuracy', \n",
    "          'is_training_metric': True, \n",
    "          'num_leaves': 144, \n",
    "          'feature_fraction': 0.9, \n",
    "          'bagging_fraction': 0.7, \n",
    "          'bagging_freq': 5, \n",
    "          'seed':2018}\n",
    "\n",
    "#         # LightGBM 모델\n",
    "#         X_train, X_eval, y_train, Y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#         train_ds = lgb.Dataset(X_train, label = y_train) \n",
    "#         test_ds = lgb.Dataset(X_eval, label = Y_eval) \n",
    "#         model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=10)\n",
    "        X_train, X_eval, y_train, Y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        eval_set = [(X_eval, Y_eval)]\n",
    "        model = lgb.LGBMClassifier(max_depth = 8,min_child_weight = 2,n_estimators=200,learning_rate = 0.009)\n",
    "        model.fit(X_train, y_train,eval_set = eval_set,early_stopping_rounds = 5,eval_metric='accuracy')\n",
    "        print(\"학습 데이터 성능\")\n",
    "        preds = model.predict(X_train)\n",
    "        print_all_reg(preds,y_train)\n",
    "\n",
    "    elif model_name == \"Cat\":     \n",
    "        # CatBoost 모델\n",
    "        X_train, X_eval, y_train, Y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        eval_set = [(X_eval, Y_eval)]\n",
    "        model = cb.CatBoostClassifier(max_depth = 6,n_estimators=200,logging_level='Silent',learning_rate = 0.001)\n",
    "        model.fit(X_train, y_train,eval_set = eval_set,early_stopping_rounds = 5)\n",
    "        print(\"학습 데이터 성능\")\n",
    "        preds = model.predict(X_train)\n",
    "        print_all_reg(preds,y_train)\n",
    "\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a562fab",
   "metadata": {},
   "source": [
    "# GBM 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485090d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 성능\n",
      "학습 데이터 성능\n",
      "model의 recall 값은 0.924\n",
      "model의 2종 오류 확률 값은 0.076\n",
      "model의 Specificity 값은 0.931\n",
      "model의 1종 오류 확률 값은 0.069\n",
      "model의 precision 값은 0.884\n",
      "model의 f1_score 값은 0.904\n",
      "model의 G-mean 값은 0.928\n",
      "model의 accuracy 값은 0.929\n",
      "Time: 0.6967sec\n",
      "model의 recall 값은 1.000\n",
      "model의 2종 오류 확률 값은 0.000\n",
      "model의 Specificity 값은 0.545\n",
      "model의 1종 오류 확률 값은 0.455\n",
      "model의 precision 값은 0.286\n",
      "model의 f1_score 값은 0.444\n",
      "model의 G-mean 값은 0.739\n",
      "model의 accuracy 값은 0.615\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 성능\")\n",
    "start_time = time.time()\n",
    "model= evaluate_regression_models(X_train, Y_train,\"GBM\")\n",
    "print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n",
    "preds = model.predict(X_test)\n",
    "print_all_reg(preds,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ada7c",
   "metadata": {},
   "source": [
    "# XGBoost 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e481e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.69054\n",
      "[1]\tvalidation_0-logloss:0.68831\n",
      "[2]\tvalidation_0-logloss:0.68583\n",
      "[3]\tvalidation_0-logloss:0.68394\n",
      "[4]\tvalidation_0-logloss:0.68219\n",
      "[5]\tvalidation_0-logloss:0.68055\n",
      "[6]\tvalidation_0-logloss:0.67876\n",
      "[7]\tvalidation_0-logloss:0.67641\n",
      "[8]\tvalidation_0-logloss:0.67486\n",
      "[9]\tvalidation_0-logloss:0.67339\n",
      "[10]\tvalidation_0-logloss:0.67152\n",
      "[11]\tvalidation_0-logloss:0.67003\n",
      "[12]\tvalidation_0-logloss:0.66841\n",
      "[13]\tvalidation_0-logloss:0.66670\n",
      "[14]\tvalidation_0-logloss:0.66529\n",
      "[15]\tvalidation_0-logloss:0.66383\n",
      "[16]\tvalidation_0-logloss:0.66237\n",
      "[17]\tvalidation_0-logloss:0.66080\n",
      "[18]\tvalidation_0-logloss:0.65933\n",
      "[19]\tvalidation_0-logloss:0.65787\n",
      "[20]\tvalidation_0-logloss:0.65576\n",
      "[21]\tvalidation_0-logloss:0.65415\n",
      "[22]\tvalidation_0-logloss:0.65252\n",
      "[23]\tvalidation_0-logloss:0.65112\n",
      "[24]\tvalidation_0-logloss:0.65003\n",
      "[25]\tvalidation_0-logloss:0.64823\n",
      "[26]\tvalidation_0-logloss:0.64651\n",
      "[27]\tvalidation_0-logloss:0.64529\n",
      "[28]\tvalidation_0-logloss:0.64394\n",
      "[29]\tvalidation_0-logloss:0.64280\n",
      "[30]\tvalidation_0-logloss:0.64147\n",
      "[31]\tvalidation_0-logloss:0.64022\n",
      "[32]\tvalidation_0-logloss:0.63892\n",
      "[33]\tvalidation_0-logloss:0.63758\n",
      "[34]\tvalidation_0-logloss:0.63659\n",
      "[35]\tvalidation_0-logloss:0.63548\n",
      "[36]\tvalidation_0-logloss:0.63452\n",
      "[37]\tvalidation_0-logloss:0.63343\n",
      "[38]\tvalidation_0-logloss:0.63202\n",
      "[39]\tvalidation_0-logloss:0.63106\n",
      "[40]\tvalidation_0-logloss:0.62952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyeonggu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\tvalidation_0-logloss:0.62816\n",
      "[42]\tvalidation_0-logloss:0.62700\n",
      "[43]\tvalidation_0-logloss:0.62583\n",
      "[44]\tvalidation_0-logloss:0.62453\n",
      "[45]\tvalidation_0-logloss:0.62337\n",
      "[46]\tvalidation_0-logloss:0.62190\n",
      "[47]\tvalidation_0-logloss:0.62101\n",
      "[48]\tvalidation_0-logloss:0.61997\n",
      "[49]\tvalidation_0-logloss:0.61891\n",
      "[50]\tvalidation_0-logloss:0.61766\n",
      "[51]\tvalidation_0-logloss:0.61657\n",
      "[52]\tvalidation_0-logloss:0.61560\n",
      "[53]\tvalidation_0-logloss:0.61455\n",
      "[54]\tvalidation_0-logloss:0.61310\n",
      "[55]\tvalidation_0-logloss:0.61179\n",
      "[56]\tvalidation_0-logloss:0.61082\n",
      "[57]\tvalidation_0-logloss:0.60933\n",
      "[58]\tvalidation_0-logloss:0.60837\n",
      "[59]\tvalidation_0-logloss:0.60711\n",
      "[60]\tvalidation_0-logloss:0.60596\n",
      "[61]\tvalidation_0-logloss:0.60517\n",
      "[62]\tvalidation_0-logloss:0.60412\n",
      "[63]\tvalidation_0-logloss:0.60333\n",
      "[64]\tvalidation_0-logloss:0.60236\n",
      "[65]\tvalidation_0-logloss:0.60112\n",
      "[66]\tvalidation_0-logloss:0.60024\n",
      "[67]\tvalidation_0-logloss:0.59931\n",
      "[68]\tvalidation_0-logloss:0.59850\n",
      "[69]\tvalidation_0-logloss:0.59756\n",
      "[70]\tvalidation_0-logloss:0.59703\n",
      "[71]\tvalidation_0-logloss:0.59582\n",
      "[72]\tvalidation_0-logloss:0.59488\n",
      "[73]\tvalidation_0-logloss:0.59379\n",
      "[74]\tvalidation_0-logloss:0.59276\n",
      "[75]\tvalidation_0-logloss:0.59192\n",
      "[76]\tvalidation_0-logloss:0.59093\n",
      "[77]\tvalidation_0-logloss:0.59018\n",
      "[78]\tvalidation_0-logloss:0.58944\n",
      "[79]\tvalidation_0-logloss:0.58864\n",
      "[80]\tvalidation_0-logloss:0.58768\n",
      "[81]\tvalidation_0-logloss:0.58685\n",
      "[82]\tvalidation_0-logloss:0.58585\n",
      "[83]\tvalidation_0-logloss:0.58512\n",
      "[84]\tvalidation_0-logloss:0.58442\n",
      "[85]\tvalidation_0-logloss:0.58356\n",
      "[86]\tvalidation_0-logloss:0.58211\n",
      "[87]\tvalidation_0-logloss:0.58112\n",
      "[88]\tvalidation_0-logloss:0.58038\n",
      "[89]\tvalidation_0-logloss:0.57938\n",
      "[90]\tvalidation_0-logloss:0.57876\n",
      "[91]\tvalidation_0-logloss:0.57761\n",
      "[92]\tvalidation_0-logloss:0.57644\n",
      "[93]\tvalidation_0-logloss:0.57572\n",
      "[94]\tvalidation_0-logloss:0.57440\n",
      "[95]\tvalidation_0-logloss:0.57363\n",
      "[96]\tvalidation_0-logloss:0.57241\n",
      "[97]\tvalidation_0-logloss:0.57085\n",
      "[98]\tvalidation_0-logloss:0.56969\n",
      "[99]\tvalidation_0-logloss:0.56874\n",
      "[100]\tvalidation_0-logloss:0.56776\n",
      "[101]\tvalidation_0-logloss:0.56658\n",
      "[102]\tvalidation_0-logloss:0.56619\n",
      "[103]\tvalidation_0-logloss:0.56533\n",
      "[104]\tvalidation_0-logloss:0.56419\n",
      "[105]\tvalidation_0-logloss:0.56293\n",
      "[106]\tvalidation_0-logloss:0.56249\n",
      "[107]\tvalidation_0-logloss:0.56131\n",
      "[108]\tvalidation_0-logloss:0.56024\n",
      "[109]\tvalidation_0-logloss:0.55976\n",
      "[110]\tvalidation_0-logloss:0.55833\n",
      "[111]\tvalidation_0-logloss:0.55715\n",
      "[112]\tvalidation_0-logloss:0.55610\n",
      "[113]\tvalidation_0-logloss:0.55533\n",
      "[114]\tvalidation_0-logloss:0.55384\n",
      "[115]\tvalidation_0-logloss:0.55322\n",
      "[116]\tvalidation_0-logloss:0.55191\n",
      "[117]\tvalidation_0-logloss:0.55133\n",
      "[118]\tvalidation_0-logloss:0.54986\n",
      "[119]\tvalidation_0-logloss:0.54904\n",
      "[120]\tvalidation_0-logloss:0.54811\n",
      "[121]\tvalidation_0-logloss:0.54689\n",
      "[122]\tvalidation_0-logloss:0.54640\n",
      "[123]\tvalidation_0-logloss:0.54591\n",
      "[124]\tvalidation_0-logloss:0.54475\n",
      "[125]\tvalidation_0-logloss:0.54402\n",
      "[126]\tvalidation_0-logloss:0.54315\n",
      "[127]\tvalidation_0-logloss:0.54237\n",
      "[128]\tvalidation_0-logloss:0.54147\n",
      "[129]\tvalidation_0-logloss:0.54023\n",
      "[130]\tvalidation_0-logloss:0.53900\n",
      "[131]\tvalidation_0-logloss:0.53823\n",
      "[132]\tvalidation_0-logloss:0.53712\n",
      "[133]\tvalidation_0-logloss:0.53615\n",
      "[134]\tvalidation_0-logloss:0.53557\n",
      "[135]\tvalidation_0-logloss:0.53444\n",
      "[136]\tvalidation_0-logloss:0.53361\n",
      "[137]\tvalidation_0-logloss:0.53300\n",
      "[138]\tvalidation_0-logloss:0.53187\n",
      "[139]\tvalidation_0-logloss:0.53117\n",
      "[140]\tvalidation_0-logloss:0.53020\n",
      "[141]\tvalidation_0-logloss:0.52915\n",
      "[142]\tvalidation_0-logloss:0.52836\n",
      "[143]\tvalidation_0-logloss:0.52739\n",
      "[144]\tvalidation_0-logloss:0.52657\n",
      "[145]\tvalidation_0-logloss:0.52584\n",
      "[146]\tvalidation_0-logloss:0.52509\n",
      "[147]\tvalidation_0-logloss:0.52445\n",
      "[148]\tvalidation_0-logloss:0.52336\n",
      "[149]\tvalidation_0-logloss:0.52270\n",
      "[150]\tvalidation_0-logloss:0.52174\n",
      "[151]\tvalidation_0-logloss:0.52122\n",
      "[152]\tvalidation_0-logloss:0.52027\n",
      "[153]\tvalidation_0-logloss:0.51966\n",
      "[154]\tvalidation_0-logloss:0.51878\n",
      "[155]\tvalidation_0-logloss:0.51807\n",
      "[156]\tvalidation_0-logloss:0.51704\n",
      "[157]\tvalidation_0-logloss:0.51618\n",
      "[158]\tvalidation_0-logloss:0.51560\n",
      "[159]\tvalidation_0-logloss:0.51506\n",
      "[160]\tvalidation_0-logloss:0.51417\n",
      "[161]\tvalidation_0-logloss:0.51359\n",
      "[162]\tvalidation_0-logloss:0.51319\n",
      "[163]\tvalidation_0-logloss:0.51228\n",
      "[164]\tvalidation_0-logloss:0.51165\n",
      "[165]\tvalidation_0-logloss:0.51106\n",
      "[166]\tvalidation_0-logloss:0.51044\n",
      "[167]\tvalidation_0-logloss:0.50989\n",
      "[168]\tvalidation_0-logloss:0.50920\n",
      "[169]\tvalidation_0-logloss:0.50874\n",
      "[170]\tvalidation_0-logloss:0.50812\n",
      "[171]\tvalidation_0-logloss:0.50748\n",
      "[172]\tvalidation_0-logloss:0.50657\n",
      "[173]\tvalidation_0-logloss:0.50594\n",
      "[174]\tvalidation_0-logloss:0.50507\n",
      "[175]\tvalidation_0-logloss:0.50444\n",
      "[176]\tvalidation_0-logloss:0.50342\n",
      "[177]\tvalidation_0-logloss:0.50260\n",
      "[178]\tvalidation_0-logloss:0.50194\n",
      "[179]\tvalidation_0-logloss:0.50126\n",
      "[180]\tvalidation_0-logloss:0.50056\n",
      "[181]\tvalidation_0-logloss:0.50003\n",
      "[182]\tvalidation_0-logloss:0.49893\n",
      "[183]\tvalidation_0-logloss:0.49812\n",
      "[184]\tvalidation_0-logloss:0.49767\n",
      "[185]\tvalidation_0-logloss:0.49715\n",
      "[186]\tvalidation_0-logloss:0.49644\n",
      "[187]\tvalidation_0-logloss:0.49555\n",
      "[188]\tvalidation_0-logloss:0.49502\n",
      "[189]\tvalidation_0-logloss:0.49458\n",
      "[190]\tvalidation_0-logloss:0.49382\n",
      "[191]\tvalidation_0-logloss:0.49302\n",
      "[192]\tvalidation_0-logloss:0.49261\n",
      "[193]\tvalidation_0-logloss:0.49170\n",
      "[194]\tvalidation_0-logloss:0.49088\n",
      "[195]\tvalidation_0-logloss:0.49037\n",
      "[196]\tvalidation_0-logloss:0.48962\n",
      "[197]\tvalidation_0-logloss:0.48929\n",
      "[198]\tvalidation_0-logloss:0.48831\n",
      "[199]\tvalidation_0-logloss:0.48780\n",
      "학습 데이터 성능\n",
      "model의 recall 값은 1.000\n",
      "model의 2종 오류 확률 값은 0.000\n",
      "model의 Specificity 값은 0.974\n",
      "model의 1종 오류 확률 값은 0.026\n",
      "model의 precision 값은 0.957\n",
      "model의 f1_score 값은 0.978\n",
      "model의 G-mean 값은 0.987\n",
      "model의 accuracy 값은 0.984\n",
      "Time: 0.7814sec\n",
      "model의 recall 값은 0.889\n",
      "model의 2종 오류 확률 값은 0.111\n",
      "model의 Specificity 값은 0.647\n",
      "model의 1종 오류 확률 값은 0.353\n",
      "model의 precision 값은 0.571\n",
      "model의 f1_score 값은 0.696\n",
      "model의 G-mean 값은 0.758\n",
      "model의 accuracy 값은 0.731\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model= evaluate_regression_models(X_train, Y_train,\"XGB\")\n",
    "print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n",
    "preds = model.predict(X_test)\n",
    "print_all_reg(preds,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46c5e5",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3000658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.697985\n",
      "[2]\tvalid_0's binary_logloss: 0.694067\n",
      "[3]\tvalid_0's binary_logloss: 0.690752\n",
      "[4]\tvalid_0's binary_logloss: 0.686988\n",
      "[5]\tvalid_0's binary_logloss: 0.683463\n",
      "[6]\tvalid_0's binary_logloss: 0.680351\n",
      "[7]\tvalid_0's binary_logloss: 0.676799\n",
      "[8]\tvalid_0's binary_logloss: 0.673348\n",
      "[9]\tvalid_0's binary_logloss: 0.670419\n",
      "[10]\tvalid_0's binary_logloss: 0.667157\n",
      "[11]\tvalid_0's binary_logloss: 0.663488\n",
      "[12]\tvalid_0's binary_logloss: 0.659556\n",
      "[13]\tvalid_0's binary_logloss: 0.656817\n",
      "[14]\tvalid_0's binary_logloss: 0.653019\n",
      "[15]\tvalid_0's binary_logloss: 0.649885\n",
      "[16]\tvalid_0's binary_logloss: 0.646195\n",
      "[17]\tvalid_0's binary_logloss: 0.643256\n",
      "[18]\tvalid_0's binary_logloss: 0.640727\n",
      "[19]\tvalid_0's binary_logloss: 0.637414\n",
      "[20]\tvalid_0's binary_logloss: 0.634103\n",
      "[21]\tvalid_0's binary_logloss: 0.631591\n",
      "[22]\tvalid_0's binary_logloss: 0.628625\n",
      "[23]\tvalid_0's binary_logloss: 0.62432\n",
      "[24]\tvalid_0's binary_logloss: 0.621997\n",
      "[25]\tvalid_0's binary_logloss: 0.619212\n",
      "[26]\tvalid_0's binary_logloss: 0.616839\n",
      "[27]\tvalid_0's binary_logloss: 0.61276\n",
      "[28]\tvalid_0's binary_logloss: 0.610617\n",
      "[29]\tvalid_0's binary_logloss: 0.606661\n",
      "[30]\tvalid_0's binary_logloss: 0.60504\n",
      "[31]\tvalid_0's binary_logloss: 0.6012\n",
      "[32]\tvalid_0's binary_logloss: 0.598982\n",
      "[33]\tvalid_0's binary_logloss: 0.596022\n",
      "[34]\tvalid_0's binary_logloss: 0.592342\n",
      "[35]\tvalid_0's binary_logloss: 0.58873\n",
      "[36]\tvalid_0's binary_logloss: 0.587318\n",
      "[37]\tvalid_0's binary_logloss: 0.584045\n",
      "[38]\tvalid_0's binary_logloss: 0.581808\n",
      "[39]\tvalid_0's binary_logloss: 0.578375\n",
      "[40]\tvalid_0's binary_logloss: 0.575\n",
      "[41]\tvalid_0's binary_logloss: 0.573727\n",
      "[42]\tvalid_0's binary_logloss: 0.570652\n",
      "[43]\tvalid_0's binary_logloss: 0.569091\n",
      "[44]\tvalid_0's binary_logloss: 0.565856\n",
      "[45]\tvalid_0's binary_logloss: 0.564009\n",
      "[46]\tvalid_0's binary_logloss: 0.560682\n",
      "[47]\tvalid_0's binary_logloss: 0.559226\n",
      "[48]\tvalid_0's binary_logloss: 0.556349\n",
      "[49]\tvalid_0's binary_logloss: 0.555128\n",
      "[50]\tvalid_0's binary_logloss: 0.553743\n",
      "[51]\tvalid_0's binary_logloss: 0.551944\n",
      "[52]\tvalid_0's binary_logloss: 0.549498\n",
      "[53]\tvalid_0's binary_logloss: 0.54776\n",
      "[54]\tvalid_0's binary_logloss: 0.546058\n",
      "[55]\tvalid_0's binary_logloss: 0.543609\n",
      "[56]\tvalid_0's binary_logloss: 0.541087\n",
      "[57]\tvalid_0's binary_logloss: 0.539518\n",
      "[58]\tvalid_0's binary_logloss: 0.538306\n",
      "[59]\tvalid_0's binary_logloss: 0.536734\n",
      "[60]\tvalid_0's binary_logloss: 0.535182\n",
      "[61]\tvalid_0's binary_logloss: 0.533423\n",
      "[62]\tvalid_0's binary_logloss: 0.53198\n",
      "[63]\tvalid_0's binary_logloss: 0.530273\n",
      "[64]\tvalid_0's binary_logloss: 0.528686\n",
      "[65]\tvalid_0's binary_logloss: 0.527031\n",
      "[66]\tvalid_0's binary_logloss: 0.525665\n",
      "[67]\tvalid_0's binary_logloss: 0.52406\n",
      "[68]\tvalid_0's binary_logloss: 0.522689\n",
      "[69]\tvalid_0's binary_logloss: 0.521132\n",
      "[70]\tvalid_0's binary_logloss: 0.519864\n",
      "[71]\tvalid_0's binary_logloss: 0.518355\n",
      "[72]\tvalid_0's binary_logloss: 0.516962\n",
      "[73]\tvalid_0's binary_logloss: 0.515739\n",
      "[74]\tvalid_0's binary_logloss: 0.514359\n",
      "[75]\tvalid_0's binary_logloss: 0.513314\n",
      "[76]\tvalid_0's binary_logloss: 0.511983\n",
      "[77]\tvalid_0's binary_logloss: 0.510651\n",
      "[78]\tvalid_0's binary_logloss: 0.509445\n",
      "[79]\tvalid_0's binary_logloss: 0.508169\n",
      "[80]\tvalid_0's binary_logloss: 0.506692\n",
      "[81]\tvalid_0's binary_logloss: 0.50492\n",
      "[82]\tvalid_0's binary_logloss: 0.503956\n",
      "[83]\tvalid_0's binary_logloss: 0.502155\n",
      "[84]\tvalid_0's binary_logloss: 0.500558\n",
      "[85]\tvalid_0's binary_logloss: 0.499436\n",
      "[86]\tvalid_0's binary_logloss: 0.498424\n",
      "[87]\tvalid_0's binary_logloss: 0.49635\n",
      "[88]\tvalid_0's binary_logloss: 0.494634\n",
      "[89]\tvalid_0's binary_logloss: 0.493729\n",
      "[90]\tvalid_0's binary_logloss: 0.491722\n",
      "[91]\tvalid_0's binary_logloss: 0.490418\n",
      "[92]\tvalid_0's binary_logloss: 0.489716\n",
      "[93]\tvalid_0's binary_logloss: 0.487761\n",
      "[94]\tvalid_0's binary_logloss: 0.487083\n",
      "[95]\tvalid_0's binary_logloss: 0.485751\n",
      "[96]\tvalid_0's binary_logloss: 0.483851\n",
      "[97]\tvalid_0's binary_logloss: 0.482596\n",
      "[98]\tvalid_0's binary_logloss: 0.481635\n",
      "[99]\tvalid_0's binary_logloss: 0.47979\n",
      "[100]\tvalid_0's binary_logloss: 0.478333\n",
      "[101]\tvalid_0's binary_logloss: 0.476453\n",
      "[102]\tvalid_0's binary_logloss: 0.475836\n",
      "[103]\tvalid_0's binary_logloss: 0.474062\n",
      "[104]\tvalid_0's binary_logloss: 0.472785\n",
      "[105]\tvalid_0's binary_logloss: 0.471902\n",
      "[106]\tvalid_0's binary_logloss: 0.470179\n",
      "[107]\tvalid_0's binary_logloss: 0.469438\n",
      "[108]\tvalid_0's binary_logloss: 0.468069\n",
      "[109]\tvalid_0's binary_logloss: 0.466885\n",
      "[110]\tvalid_0's binary_logloss: 0.465225\n",
      "[111]\tvalid_0's binary_logloss: 0.464005\n",
      "[112]\tvalid_0's binary_logloss: 0.463244\n",
      "[113]\tvalid_0's binary_logloss: 0.461497\n",
      "[114]\tvalid_0's binary_logloss: 0.459902\n",
      "[115]\tvalid_0's binary_logloss: 0.459364\n",
      "[116]\tvalid_0's binary_logloss: 0.458072\n",
      "[117]\tvalid_0's binary_logloss: 0.456861\n",
      "[118]\tvalid_0's binary_logloss: 0.455688\n",
      "[119]\tvalid_0's binary_logloss: 0.454812\n",
      "[120]\tvalid_0's binary_logloss: 0.453638\n",
      "[121]\tvalid_0's binary_logloss: 0.45272\n",
      "[122]\tvalid_0's binary_logloss: 0.451486\n",
      "[123]\tvalid_0's binary_logloss: 0.449853\n",
      "[124]\tvalid_0's binary_logloss: 0.449184\n",
      "[125]\tvalid_0's binary_logloss: 0.44805\n",
      "[126]\tvalid_0's binary_logloss: 0.446998\n",
      "[127]\tvalid_0's binary_logloss: 0.446037\n",
      "[128]\tvalid_0's binary_logloss: 0.444933\n",
      "[129]\tvalid_0's binary_logloss: 0.443829\n",
      "[130]\tvalid_0's binary_logloss: 0.443054\n",
      "[131]\tvalid_0's binary_logloss: 0.442437\n",
      "[132]\tvalid_0's binary_logloss: 0.441196\n",
      "[133]\tvalid_0's binary_logloss: 0.440287\n",
      "[134]\tvalid_0's binary_logloss: 0.43956\n",
      "[135]\tvalid_0's binary_logloss: 0.438352\n",
      "[136]\tvalid_0's binary_logloss: 0.437475\n",
      "[137]\tvalid_0's binary_logloss: 0.436452\n",
      "[138]\tvalid_0's binary_logloss: 0.435279\n",
      "[139]\tvalid_0's binary_logloss: 0.434813\n",
      "[140]\tvalid_0's binary_logloss: 0.433971\n",
      "[141]\tvalid_0's binary_logloss: 0.433019\n",
      "[142]\tvalid_0's binary_logloss: 0.432045\n",
      "[143]\tvalid_0's binary_logloss: 0.43115\n",
      "[144]\tvalid_0's binary_logloss: 0.430176\n",
      "[145]\tvalid_0's binary_logloss: 0.429306\n",
      "[146]\tvalid_0's binary_logloss: 0.428135\n",
      "[147]\tvalid_0's binary_logloss: 0.427056\n",
      "[148]\tvalid_0's binary_logloss: 0.426679\n",
      "[149]\tvalid_0's binary_logloss: 0.425731\n",
      "[150]\tvalid_0's binary_logloss: 0.424827\n",
      "[151]\tvalid_0's binary_logloss: 0.423923\n",
      "[152]\tvalid_0's binary_logloss: 0.422894\n",
      "[153]\tvalid_0's binary_logloss: 0.42249\n",
      "[154]\tvalid_0's binary_logloss: 0.421746\n",
      "[155]\tvalid_0's binary_logloss: 0.420971\n",
      "[156]\tvalid_0's binary_logloss: 0.420305\n",
      "[157]\tvalid_0's binary_logloss: 0.419314\n",
      "[158]\tvalid_0's binary_logloss: 0.418485\n",
      "[159]\tvalid_0's binary_logloss: 0.417778\n",
      "[160]\tvalid_0's binary_logloss: 0.416797\n",
      "[161]\tvalid_0's binary_logloss: 0.416073\n",
      "[162]\tvalid_0's binary_logloss: 0.415909\n",
      "[163]\tvalid_0's binary_logloss: 0.415198\n",
      "[164]\tvalid_0's binary_logloss: 0.414247\n",
      "[165]\tvalid_0's binary_logloss: 0.41357\n",
      "[166]\tvalid_0's binary_logloss: 0.413712\n",
      "[167]\tvalid_0's binary_logloss: 0.413017\n",
      "[168]\tvalid_0's binary_logloss: 0.4121\n",
      "[169]\tvalid_0's binary_logloss: 0.411413\n",
      "[170]\tvalid_0's binary_logloss: 0.410531\n",
      "[171]\tvalid_0's binary_logloss: 0.409124\n",
      "[172]\tvalid_0's binary_logloss: 0.40844\n",
      "[173]\tvalid_0's binary_logloss: 0.407781\n",
      "[174]\tvalid_0's binary_logloss: 0.406405\n",
      "[175]\tvalid_0's binary_logloss: 0.405719\n",
      "[176]\tvalid_0's binary_logloss: 0.405095\n",
      "[177]\tvalid_0's binary_logloss: 0.403896\n",
      "[178]\tvalid_0's binary_logloss: 0.403165\n",
      "[179]\tvalid_0's binary_logloss: 0.403333\n",
      "[180]\tvalid_0's binary_logloss: 0.402559\n",
      "[181]\tvalid_0's binary_logloss: 0.40185\n",
      "[182]\tvalid_0's binary_logloss: 0.401231\n",
      "[183]\tvalid_0's binary_logloss: 0.400473\n",
      "[184]\tvalid_0's binary_logloss: 0.399823\n",
      "[185]\tvalid_0's binary_logloss: 0.399084\n",
      "[186]\tvalid_0's binary_logloss: 0.399007\n",
      "[187]\tvalid_0's binary_logloss: 0.398284\n",
      "[188]\tvalid_0's binary_logloss: 0.396994\n",
      "[189]\tvalid_0's binary_logloss: 0.39628\n",
      "[190]\tvalid_0's binary_logloss: 0.395662\n",
      "[191]\tvalid_0's binary_logloss: 0.394845\n",
      "[192]\tvalid_0's binary_logloss: 0.395153\n",
      "[193]\tvalid_0's binary_logloss: 0.395472\n",
      "[194]\tvalid_0's binary_logloss: 0.394963\n",
      "[195]\tvalid_0's binary_logloss: 0.394024\n",
      "[196]\tvalid_0's binary_logloss: 0.393516\n",
      "[197]\tvalid_0's binary_logloss: 0.39291\n",
      "[198]\tvalid_0's binary_logloss: 0.392038\n",
      "[199]\tvalid_0's binary_logloss: 0.392328\n",
      "[200]\tvalid_0's binary_logloss: 0.391746\n",
      "학습 데이터 성능\n",
      "model의 recall 값은 1.000\n",
      "model의 2종 오류 확률 값은 0.000\n",
      "model의 Specificity 값은 0.958\n",
      "model의 1종 오류 확률 값은 0.042\n",
      "model의 precision 값은 0.928\n",
      "model의 f1_score 값은 0.962\n",
      "model의 G-mean 값은 0.979\n",
      "model의 accuracy 값은 0.973\n",
      "Time: 0.1076sec\n",
      "model의 recall 값은 1.000\n",
      "model의 2종 오류 확률 값은 0.000\n",
      "model의 Specificity 값은 0.706\n",
      "model의 1종 오류 확률 값은 0.294\n",
      "model의 precision 값은 0.643\n",
      "model의 f1_score 값은 0.783\n",
      "model의 G-mean 값은 0.840\n",
      "model의 accuracy 값은 0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyeonggu\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model= evaluate_regression_models(X_train, Y_train,\"Light\")\n",
    "print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n",
    "preds = model.predict(X_test)\n",
    "print_all_reg(preds,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc0682",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa66bee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 성능\n",
      "model의 recall 값은 1.000\n",
      "model의 2종 오류 확률 값은 0.000\n",
      "model의 Specificity 값은 0.919\n",
      "model의 1종 오류 확률 값은 0.081\n",
      "model의 precision 값은 0.855\n",
      "model의 f1_score 값은 0.922\n",
      "model의 G-mean 값은 0.958\n",
      "model의 accuracy 값은 0.945\n",
      "Time: 1.7086sec\n",
      "model의 recall 값은 1.000\n",
      "model의 2종 오류 확률 값은 0.000\n",
      "model의 Specificity 값은 0.667\n",
      "model의 1종 오류 확률 값은 0.333\n",
      "model의 precision 값은 0.571\n",
      "model의 f1_score 값은 0.727\n",
      "model의 G-mean 값은 0.816\n",
      "model의 accuracy 값은 0.769\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model= evaluate_regression_models(X_train, Y_train,\"Cat\")\n",
    "print(\"Time: {:.4f}sec\".format((time.time() - start_time)))\n",
    "preds = model.predict(X_test)\n",
    "print_all_reg(preds,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95172f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312b63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b3b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
