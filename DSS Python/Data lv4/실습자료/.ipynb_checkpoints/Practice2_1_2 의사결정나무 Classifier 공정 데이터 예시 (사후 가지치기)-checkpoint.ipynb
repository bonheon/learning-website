{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2146817",
   "metadata": {},
   "source": [
    "# 의사결정나무(Decison Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155a1d5",
   "metadata": {},
   "source": [
    "#### **사후 가지치기**\n",
    ": 나무가 완성된 후에 하단 노드부터 유의미하지 않다고 판단되는 Subtree를 끝노드로 변환시키는 방법    \n",
    "\n",
    "#### [Cost Complexity Pruning](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html)    \n",
    "$R_\\alpha(T) = R(T) + \\alpha\\vert T \\vert$\n",
    "\n",
    "  - 위의 비용복잡도(Cost complexity) 식을 최소화 시키는 과정(CCP)\n",
    "  - Weakest link pruning이라고도 한다.\n",
    "  - 가지가 있을 때와 처낼 때 불순도의 차이가 거의 없는 가지(Weakest Link)를 가지치기하는 메커니즘\n",
    "  - 모든 Subtree를 고려하진 않아 Local Minima에 빠질 수 있다.\n",
    "\n",
    "    \n",
    "참고 : https://zephyrus1111.tistory.com/131\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6452b",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b822863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib\n",
    "#한글꺠짐 방지\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c20fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/class_balance.csv\",encoding=\"EUC-KR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59f8f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X466</th>\n",
       "      <th>X467</th>\n",
       "      <th>X468</th>\n",
       "      <th>X469</th>\n",
       "      <th>X470</th>\n",
       "      <th>X471</th>\n",
       "      <th>X472</th>\n",
       "      <th>X473</th>\n",
       "      <th>X474</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.530189</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>0.359864</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>0.322190</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.274876</td>\n",
       "      <td>0.210238</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.341478</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.469654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.447466</td>\n",
       "      <td>0.189233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523785</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.210356</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.439175</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360781</td>\n",
       "      <td>0.369653</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>0.528684</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.516722</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.376835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460910</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.561615</td>\n",
       "      <td>0.415328</td>\n",
       "      <td>0.313214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263068</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.638747</td>\n",
       "      <td>0.660074</td>\n",
       "      <td>0.520392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110711</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.608414</td>\n",
       "      <td>0.212062</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.360022</td>\n",
       "      <td>0.396033</td>\n",
       "      <td>0.382803</td>\n",
       "      <td>0.070771</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>0.920884</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.337454</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>0.147860</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.508628</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>0.192378</td>\n",
       "      <td>0.061866</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.481919</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.407911</td>\n",
       "      <td>0.336052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132582</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.275930</td>\n",
       "      <td>0.364365</td>\n",
       "      <td>0.302236</td>\n",
       "      <td>0.376615</td>\n",
       "      <td>0.485135</td>\n",
       "      <td>0.627270</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.420272</td>\n",
       "      <td>0.367047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.586806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.343042</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.143012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.785179</td>\n",
       "      <td>0.271804</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.229526</td>\n",
       "      <td>0.244320</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.875565</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.337684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221768</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.024317</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>0.398833</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.164343</td>\n",
       "      <td>0.571191</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.401357</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.592648</td>\n",
       "      <td>0.498146</td>\n",
       "      <td>0.340946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.309061</td>\n",
       "      <td>0.178988</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.179953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0    0.457896  0.530189  0.276976  0.359864  0.193059  0.322190  0.706897   \n",
       "1    0.607100  0.341478  0.518992  0.395300  0.042071  0.469654  0.750000   \n",
       "2    0.360781  0.369653  0.341039  0.021697  0.181737  0.528684  0.491379   \n",
       "3    0.460910  0.413500  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "4    0.263068  0.279821  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "249  0.360022  0.396033  0.382803  0.070771  0.143308  0.920884  0.586207   \n",
       "250  0.508628  0.437628  0.192378  0.061866  0.168425  0.481919  0.715517   \n",
       "251  0.275930  0.364365  0.302236  0.376615  0.485135  0.627270  0.594828   \n",
       "252  0.785179  0.271804  0.400189  0.457851  0.229526  0.244320  0.396552   \n",
       "253  0.164343  0.571191  0.324472  0.401357  0.249864  0.229873  0.448276   \n",
       "\n",
       "           X8        X9       X10  ...      X466      X467      X468  \\\n",
       "0    0.553781  0.653894  0.375204  ...  0.246376  0.711806  0.008532   \n",
       "1    0.542031  0.447466  0.189233  ...  0.523785  0.760417  0.030930   \n",
       "2    0.516722  0.300371  0.376835  ...  0.185769  0.659722  0.005333   \n",
       "3    0.561615  0.415328  0.313214  ...  0.246376  0.000000  1.000000   \n",
       "4    0.638747  0.660074  0.520392  ...  0.110711  0.517361  0.023677   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "249  0.636336  0.337454  0.432300  ...  0.000000  0.597222  0.016212   \n",
       "250  0.270563  0.407911  0.336052  ...  0.132582  0.975694  0.017065   \n",
       "251  0.435673  0.420272  0.367047  ...  0.246376  0.586806  0.008532   \n",
       "252  0.875565  0.110012  0.337684  ...  0.221768  0.767361  0.024317   \n",
       "253  0.592648  0.498146  0.340946  ...  0.214622  0.621528  0.020904   \n",
       "\n",
       "         X469      X470      X471      X472      X473      X474  Y  \n",
       "0    0.013672  0.008467  0.402240  0.238811  0.274876  0.210238 -1  \n",
       "1    0.033203  0.029759  0.210356  0.309339  0.328358  0.439175 -1  \n",
       "2    0.003906  0.005311  0.381877  0.208171  0.208955  0.155761 -1  \n",
       "3    1.000000  1.000000  0.381877  0.208171  0.208955  0.155761 -1  \n",
       "4    0.022461  0.023447  0.608414  0.212062  0.268657  0.092827 -1  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "249  0.013672  0.015997  0.045307  0.147860  0.171642  0.000000  1  \n",
       "250  0.015625  0.016114  0.543689  0.227626  0.320896  0.111165  1  \n",
       "251  0.015625  0.008613  0.343042  0.151751  0.164179  0.143012  1  \n",
       "252  0.019531  0.023461  0.509709  0.398833  0.440299  0.185945  1  \n",
       "253  0.018555  0.020352  0.309061  0.178988  0.201493  0.179953  1  \n",
       "\n",
       "[254 rows x 475 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aca0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,Y 분할\n",
    "Y=data[\"Y\"].copy()\n",
    "X=data.drop(\"Y\",axis=1)\n",
    "X.head(3)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=22,shuffle =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092e8a5",
   "metadata": {},
   "source": [
    "[[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)]  \n",
    "**sklearn.model_selection.train_test_split**\n",
    "- **test_size** : float or int, default = 0.25, 정수값일시 test사이즈로 설정하고 싶은 샘플 수 입력\n",
    "- **train_size** : float or int, default = None\n",
    "- **random_state** : int, default = None, 랜덤 seed값 설정, 같은 seed 내에선 동일결과 추출 \n",
    "- **shuffle** : bool, default = True, 데이터셋 무작위 추출, 시계열 데이터와 같이 순차적 추출이 필요한 경우엔 Shuffle = False!\n",
    "- **stratify** : array-like, default = None, True일시 계층적 샘플링 진행 ([참고](https://www.investopedia.com/terms/stratified_random_sampling.asp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a71bc",
   "metadata": {},
   "source": [
    "### 2. 평가 지표 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915b02e",
   "metadata": {},
   "source": [
    "![Confusion Matrix](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)\n",
    "\n",
    "###### 이미지 출처 : https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3227a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 출력 함수\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_all_reg(Y_test,pred):\n",
    "    # Specificity를 구하기 위해 confusion matrix를 이용\n",
    "    cm1 = confusion_matrix(Y_test,pred)\n",
    "    specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    #결과 검사\n",
    "    #recall = cm1[1,1]/(cm1[1,1]+cm1[1,0])\n",
    "    #pre = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "\n",
    "    G_mean = recall_score(Y_test,pred) * specificity1\n",
    "    \n",
    "    print(\"model의 recall 값은 {:.3f}\".format(recall_score(Y_test,pred)))\n",
    "    print(\"model의 2종 오류 확률 값은 {:.3f}\".format(1-recall_score(Y_test,pred)))\n",
    "    print(\"model의 Specificity 값은 {:.3f}\".format(specificity1))\n",
    "    print(\"model의 1종 오류 확률 값은 {:.3f}\".format(1-specificity1))\n",
    "    print(\"model의 precision 값은 {:.3f}\".format(precision_score(Y_test,pred)))\n",
    "    print(\"model의 f1_score 값은 {:.3f}\".format(f1_score(Y_test,pred)))\n",
    "    print(\"model의 G-mean 값은 {:.3f}\".format(np.sqrt(G_mean)))\n",
    "    print(\"model의 accuracy 값은 {:.3f}\".format(accuracy_score(Y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ec9ce",
   "metadata": {},
   "source": [
    "### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a34ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ccp_alpha_list = list(np.arange(0.25,0,-0.001)) # 0.25부터 0까지 0.001씩 감소\n",
    "ccp_alpha_list2 = list(np.arange(0,0.25,0.001)) # 0부터 0.25까지 0.001씩 증가\n",
    "\n",
    "#ccp_alpha_list = np.logspace(-10, 0, num=200)\n",
    "#ccp_alpha_list2 = np.logspace(-10, 0, num=200)\n",
    "train_scores =[]\n",
    "test_scores =[]\n",
    "for alpha in ccp_alpha_list:\n",
    "    clf = DecisionTreeClassifier(ccp_alpha= alpha) # ccp_alpha 값보다 작으면서 비용복잡도가 가장 큰 Subtree\n",
    "    clf.fit(X_train,Y_train) # 학습용 데이터로 모델 학습\n",
    "    \n",
    "    preds_train = clf.predict(X_train) # 모델 예측\n",
    "    preds = clf.predict(X_test)\n",
    "    \n",
    "    train_scores.append(1-accuracy_score(Y_train,preds_train)) # 학습용 데이터 오분류율\n",
    "    test_scores.append(1-accuracy_score(Y_test,preds)) # 테스트 데이터 오분류율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1a5e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ccp-alpha 값을 변화시키면서 얻은 모델 결과 시각화\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"ccp alpha\")\n",
    "ax.set_ylabel(\"1-accuracy\")\n",
    "#ax.set_title(\"나무 복잡도 증가에 따른 오분류율 그래프\")\n",
    "ax.plot(ccp_alpha_list, pd.Series(train_scores).rolling(10,center =True).mean(),  label=\"train data\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alpha_list, pd.Series(test_scores).rolling(10,center=True).mean(),  label=\"test data\", drawstyle=\"steps-post\")\n",
    "\n",
    "#ax.plot(ccp_alpha_list, train_scores, drawstyle=\"steps-post\")\n",
    "#ax.plot(ccp_alpha_list, test_scores, drawstyle=\"steps-post\")\n",
    "\n",
    "ax.legend()\n",
    "#plt.xlim(0.7)\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e90ad7",
   "metadata": {},
   "source": [
    "- 테스트 데이터에서 오분류율이 가장 낮은 alpha = 0.02를 최적값으로 선택!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11f0884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model의 recall 값은 0.872\n",
      "model의 2종 오류 확률 값은 0.128\n",
      "model의 Specificity 값은 0.923\n",
      "model의 1종 오류 확률 값은 0.077\n",
      "model의 precision 값은 0.893\n",
      "model의 f1_score 값은 0.882\n",
      "model의 G-mean 값은 0.897\n",
      "model의 accuracy 값은 0.901\n",
      " \n",
      "model의 recall 값은 0.722\n",
      "model의 2종 오류 확률 값은 0.278\n",
      "model의 Specificity 값은 0.848\n",
      "model의 1종 오류 확률 값은 0.152\n",
      "model의 precision 값은 0.722\n",
      "model의 f1_score 값은 0.722\n",
      "model의 G-mean 값은 0.783\n",
      "model의 accuracy 값은 0.804\n"
     ]
    }
   ],
   "source": [
    "# 최적 ccp-alpha로 모델 학습\n",
    "\n",
    "alpha = 0.02\n",
    "clf = DecisionTreeClassifier(ccp_alpha= alpha)  \n",
    "clf.fit(X_train,Y_train)\n",
    "preds = clf.predict(X_test)\n",
    "preds_train = clf.predict(X_train) # 훈련용 X 데이터셋으로 예측값 생성\n",
    "print_all_reg(Y_train,preds_train) # 실제 y값과 예측값을 비교하여 성능지표 출력\n",
    "print(\" \")\n",
    "print_all_reg(Y_test,preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e81d91ba51e1bf9900dd7d036cbe3d31d033e3ae1051184964e8f8743fed6bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
