{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d181c0f7",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machine(GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e28d8c",
   "metadata": {},
   "source": [
    "- GBMì€ ğ‘šë¼ìš´ë“œì˜ ë² ì´ìŠ¤ ëª¨ë¸ $â„_ğ‘š$ ì´ $(m-1)$ë¼ìš´ë“œê¹Œì§€ì˜ ë² ì´ìŠ¤ ëª¨ë¸ì„ ê²°í•©í•œ $ğ»ğ‘šâˆ’1=â„_1+â‹¯+â„_{ğ‘šâˆ’1}$ì˜ ì˜ˆì¸¡ ì˜¤ë¥˜ë¥¼ í•™ìŠµí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜\n",
    "- ì¦‰, ì´ì „ ê²°í•© ëª¨ë¸ $H_{m-1}$ì˜ ì˜ˆì¸¡ ì˜¤ë¥˜ëŠ” ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ëœë¤ ë…¸ì´ì¦ˆê°€ ì•„ë‹Œ ì•„ì§ê¹Œì§€ í•™ìŠµ ëª»í•œ íŠ¹ì§•ì´ë¼ê³  ê°€ì •í•¨\n",
    "- ì•„ë˜ëŠ” GBMì˜ ì˜ˆì‹œë¡œ, $â„_2$ëŠ” $â„_1$ì˜ ì”ì°¨ $(ğ‘¦-\\hat{ğ‘¦_1})$ë¥¼ , $â„_3$ëŠ” $ğ»_2=â„_1+â„_2$ì˜ ì”ì°¨ $(ğ‘¦-\\hat{ğ‘¦_1}-\\hat{ğ‘¦_2})$ ë¥¼ í•™ìŠµí•˜ê³  ìµœì¢…ì ìœ¼ë¡œ $â„_1,â„_2,â„_3$ë¥¼ ê²°í•©í•˜ì—¬ ê°•í•œ ëª¨ë¸ $ğ»_3=â„_1+â„_2+â„_3=ğ»_2+â„_3$ë¥¼ ë§Œë“¦  \n",
    "- ë¶„ë¥˜ë¬¸ì œì—ì„œ GBMì€ ë¡œì§€ìŠ¤í‹± íšŒê·€ì²˜ëŸ¼ ì„±ê³µì¼ í™•ë¥ ì„ ì˜ˆì¸¡í•¨(ì„±ê³µì„ ë¶ˆëŸ‰ìœ¼ë¡œ ê°„ì£¼í•˜ë©´ ë¶ˆëŸ‰ í™•ë¥ ì„ ì˜ˆì¸¡) \n",
    "  \n",
    "\n",
    "![gbm](img\\ë¶€ìŠ¤íŒ….png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6452b",
   "metadata": {},
   "source": [
    "### 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b822863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib\n",
    "#í•œê¸€êº ì§ ë°©ì§€\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c20fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/class_balance.csv\",encoding=\"EUC-KR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59f8f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X466</th>\n",
       "      <th>X467</th>\n",
       "      <th>X468</th>\n",
       "      <th>X469</th>\n",
       "      <th>X470</th>\n",
       "      <th>X471</th>\n",
       "      <th>X472</th>\n",
       "      <th>X473</th>\n",
       "      <th>X474</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.530189</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>0.359864</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>0.322190</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.653894</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.402240</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.274876</td>\n",
       "      <td>0.210238</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.341478</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.469654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.447466</td>\n",
       "      <td>0.189233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523785</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>0.210356</td>\n",
       "      <td>0.309339</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.439175</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360781</td>\n",
       "      <td>0.369653</td>\n",
       "      <td>0.341039</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>0.528684</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.516722</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.376835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460910</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.561615</td>\n",
       "      <td>0.415328</td>\n",
       "      <td>0.313214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>0.208171</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263068</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>0.535685</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>0.242326</td>\n",
       "      <td>0.408966</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.638747</td>\n",
       "      <td>0.660074</td>\n",
       "      <td>0.520392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110711</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.608414</td>\n",
       "      <td>0.212062</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.360022</td>\n",
       "      <td>0.396033</td>\n",
       "      <td>0.382803</td>\n",
       "      <td>0.070771</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>0.920884</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.636336</td>\n",
       "      <td>0.337454</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>0.147860</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.508628</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>0.192378</td>\n",
       "      <td>0.061866</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.481919</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.407911</td>\n",
       "      <td>0.336052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132582</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.111165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.275930</td>\n",
       "      <td>0.364365</td>\n",
       "      <td>0.302236</td>\n",
       "      <td>0.376615</td>\n",
       "      <td>0.485135</td>\n",
       "      <td>0.627270</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.420272</td>\n",
       "      <td>0.367047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.586806</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.343042</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.143012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.785179</td>\n",
       "      <td>0.271804</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.229526</td>\n",
       "      <td>0.244320</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.875565</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.337684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221768</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.024317</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>0.398833</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.164343</td>\n",
       "      <td>0.571191</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.401357</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.592648</td>\n",
       "      <td>0.498146</td>\n",
       "      <td>0.340946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.309061</td>\n",
       "      <td>0.178988</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.179953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows Ã— 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0    0.457896  0.530189  0.276976  0.359864  0.193059  0.322190  0.706897   \n",
       "1    0.607100  0.341478  0.518992  0.395300  0.042071  0.469654  0.750000   \n",
       "2    0.360781  0.369653  0.341039  0.021697  0.181737  0.528684  0.491379   \n",
       "3    0.460910  0.413500  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "4    0.263068  0.279821  0.535685  0.302794  0.242326  0.408966  0.646552   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "249  0.360022  0.396033  0.382803  0.070771  0.143308  0.920884  0.586207   \n",
       "250  0.508628  0.437628  0.192378  0.061866  0.168425  0.481919  0.715517   \n",
       "251  0.275930  0.364365  0.302236  0.376615  0.485135  0.627270  0.594828   \n",
       "252  0.785179  0.271804  0.400189  0.457851  0.229526  0.244320  0.396552   \n",
       "253  0.164343  0.571191  0.324472  0.401357  0.249864  0.229873  0.448276   \n",
       "\n",
       "           X8        X9       X10  ...      X466      X467      X468  \\\n",
       "0    0.553781  0.653894  0.375204  ...  0.246376  0.711806  0.008532   \n",
       "1    0.542031  0.447466  0.189233  ...  0.523785  0.760417  0.030930   \n",
       "2    0.516722  0.300371  0.376835  ...  0.185769  0.659722  0.005333   \n",
       "3    0.561615  0.415328  0.313214  ...  0.246376  0.000000  1.000000   \n",
       "4    0.638747  0.660074  0.520392  ...  0.110711  0.517361  0.023677   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "249  0.636336  0.337454  0.432300  ...  0.000000  0.597222  0.016212   \n",
       "250  0.270563  0.407911  0.336052  ...  0.132582  0.975694  0.017065   \n",
       "251  0.435673  0.420272  0.367047  ...  0.246376  0.586806  0.008532   \n",
       "252  0.875565  0.110012  0.337684  ...  0.221768  0.767361  0.024317   \n",
       "253  0.592648  0.498146  0.340946  ...  0.214622  0.621528  0.020904   \n",
       "\n",
       "         X469      X470      X471      X472      X473      X474  Y  \n",
       "0    0.013672  0.008467  0.402240  0.238811  0.274876  0.210238 -1  \n",
       "1    0.033203  0.029759  0.210356  0.309339  0.328358  0.439175 -1  \n",
       "2    0.003906  0.005311  0.381877  0.208171  0.208955  0.155761 -1  \n",
       "3    1.000000  1.000000  0.381877  0.208171  0.208955  0.155761 -1  \n",
       "4    0.022461  0.023447  0.608414  0.212062  0.268657  0.092827 -1  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "249  0.013672  0.015997  0.045307  0.147860  0.171642  0.000000  1  \n",
       "250  0.015625  0.016114  0.543689  0.227626  0.320896  0.111165  1  \n",
       "251  0.015625  0.008613  0.343042  0.151751  0.164179  0.143012  1  \n",
       "252  0.019531  0.023461  0.509709  0.398833  0.440299  0.185945  1  \n",
       "253  0.018555  0.020352  0.309061  0.178988  0.201493  0.179953  1  \n",
       "\n",
       "[254 rows x 475 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aca0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,Y ë¶„í• \n",
    "Y=data[\"Y\"].copy()\n",
    "X=data.drop(\"Y\",axis=1)\n",
    "X.head(3)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=22,shuffle =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a6bda",
   "metadata": {},
   "source": [
    "[[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)]  \n",
    "**sklearn.model_selection.train_test_split**\n",
    "- **test_size** : float or int, default = 0.25, ì •ìˆ˜ê°’ì¼ì‹œ testì‚¬ì´ì¦ˆë¡œ ì„¤ì •í•˜ê³  ì‹¶ì€ ìƒ˜í”Œ ìˆ˜ ì…ë ¥\n",
    "- **train_size** : float or int, default = None\n",
    "- **random_state** : int, default = None, ëœë¤ seedê°’ ì„¤ì •, ê°™ì€ seed ë‚´ì—ì„  ë™ì¼ê²°ê³¼ ì¶”ì¶œ \n",
    "- **shuffle** : bool, default = True, ë°ì´í„°ì…‹ ë¬´ì‘ìœ„ ì¶”ì¶œ, ì‹œê³„ì—´ ë°ì´í„°ì™€ ê°™ì´ ìˆœì°¨ì  ì¶”ì¶œì´ í•„ìš”í•œ ê²½ìš°ì—” Shuffle = False!\n",
    "- **stratify** : array-like, default = None, Trueì¼ì‹œ ê³„ì¸µì  ìƒ˜í”Œë§ ì§„í–‰ ([ì°¸ê³ ](https://www.investopedia.com/terms/stratified_random_sampling.asp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a71bc",
   "metadata": {},
   "source": [
    "### 2. í‰ê°€ ì§€í‘œ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cccda2",
   "metadata": {},
   "source": [
    "![Confusion Matrix](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)\n",
    "\n",
    "###### ì´ë¯¸ì§€ ì¶œì²˜ : https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3227a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ì§€í‘œ ì¶œë ¥ í•¨ìˆ˜\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_all_reg(Y_test,pred):\n",
    "    # Specificityë¥¼ êµ¬í•˜ê¸° ìœ„í•´ confusion matrixë¥¼ ì´ìš©\n",
    "    cm1 = confusion_matrix(Y_test,pred)\n",
    "    specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    #ê²°ê³¼ ê²€ì‚¬\n",
    "    #recall = cm1[1,1]/(cm1[1,1]+cm1[1,0])\n",
    "    #pre = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "\n",
    "    G_mean = recall_score(Y_test,pred) * specificity1\n",
    "    \n",
    "    print(\"modelì˜ recall ê°’ì€ {:.3f}\".format(recall_score(Y_test,pred)))\n",
    "    print(\"modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ {:.3f}\".format(1-recall_score(Y_test,pred)))\n",
    "    print(\"modelì˜ Specificity ê°’ì€ {:.3f}\".format(specificity1))\n",
    "    print(\"modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ {:.3f}\".format(1-specificity1))\n",
    "    print(\"modelì˜ precision ê°’ì€ {:.3f}\".format(precision_score(Y_test,pred)))\n",
    "    print(\"modelì˜ f1_score ê°’ì€ {:.3f}\".format(f1_score(Y_test,pred)))\n",
    "    print(\"modelì˜ G-mean ê°’ì€ {:.3f}\".format(np.sqrt(G_mean)))\n",
    "    print(\"modelì˜ accuracy ê°’ì€ {:.3f}\".format(accuracy_score(Y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ec9ce",
   "metadata": {},
   "source": [
    "### 3. ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f39a4",
   "metadata": {},
   "source": [
    "[[GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)]         \n",
    "**ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°** \n",
    "- **loss** : {â€˜log_lossâ€™, â€˜devianceâ€™, â€˜exponentialâ€™}, default=â€™log_lossâ€™, ê²½ì‚¬í•˜ê°•ë²•ì„ í™œìš©í•œ ì˜ˆì¸¡ì˜¤ë¥˜ í•™ìŠµê³¼ì •ì—ì„œ ì‚¬ìš©í•  ì†ì‹¤í•¨ìˆ˜ \n",
    "- **learning_rate** : float, default=0.1, í•™ìŠµë¥  ì„¤ì •\n",
    "    - ë„ˆë¬´ ì‘ì„ì‹œ : ì˜ˆì¸¡ì„±ëŠ¥ì€ ë†’ì•„ì§ˆ ìˆ˜ ìˆìœ¼ë‚˜, í•™ìŠµì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ê³  local minima ë¬¸ì œê°€ ë°œìƒ í•  ìˆ˜ ìˆìŒ. ë² ì´ìŠ¤ ëª¨ë¸ì˜ ì˜í–¥ë ¥ì´ ê³¼ë„í•˜ê²Œ ìˆ˜ì¶•ë˜ì–´ ê³¼ì†Œì í•©\n",
    "    - ë„ˆë¬´ í´ ì‹œ : í•™ìŠµì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ global mimimumê°’ì„ ì°¾ì§€ ëª»í•  ìˆ˜ ìˆìœ¼ë©°, ë² ì´ìŠ¤ ëª¨ë¸ ì˜í–¥ë ¥ì´ ê³¼ë„í•˜ê²Œ ì»¤ì ¸ ê³¼ì í•©ì´ ë‚˜íƒ€ë‚¨.\n",
    "- **n_estimators** : int, default=100, ë² ì´ìŠ¤ëª¨ë¸ì˜ ê°œìˆ˜ë¡œ ë§ì„ìˆ˜ë¡ ì˜ˆì¸¡ì„±ëŠ¥ì€ ë†’ì•„ì§ˆ ìˆ˜ ìˆìœ¼ë‚˜ í•™ìŠµì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦°ë‹¤.\n",
    "- **max_depth** : int, default = 3, ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ê¹Šì´ë¥¼ ì„¤ì •. ê°’ì´ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ë³µì¡ë„ê°€ ì˜¬ë¼ê°„ë‹¤.\n",
    "- **min_samples_split** : int or float, default = 2, ìì‹ë…¸ë“œë¥¼ ë¶„í• í•˜ëŠ”ë° í•„ìš”í•œ ìµœì†Œ ìƒ˜í”Œì˜ ìˆ˜\n",
    "- **min_samples_leaf** : int or float, default = 1, leaf nodeì—ì„œ í•„ìš”í•œ ìµœì†Œ ìƒ˜í’€ìˆ˜ì´ë©°, ë„ˆë¬´ ì ì„ ì‹œ ê³¼ì í•© ë°œìƒ\n",
    "- **max_leaf_nodes** : int, default=None, ìµœëŒ€ leaf node ìˆ˜ ì œí•œ\n",
    "- **validation_fraction** : float, default=0.1, í›ˆë ¨ë°ì´í„° ì¤‘ ì„¤ì • ë¹„ìœ¨ë§Œí¼ ê²€ì¦ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ í™œìš©í•œë‹¤. \n",
    "- **n_iter_no_change** : int, default=None, validation_fractionì—ì„œ ì„¤ì •í•œ ê²€ì¦ë°ì´í„°ì…‹ì—ì„œ n_iter_no_changeì— ì§€ì •í•œ ë°˜ë³µ íšŸìˆ˜ë™ì•ˆ ê²€ì¦ì ìˆ˜ê°€ ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ ì¡°ê¸°ì¢…ë£Œí•œë‹¤.\n",
    "- **ccp_alpha** : non-negative float, default=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a34ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7,shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43894478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n",
      "modelì˜ recall ê°’ì€ 0.795\n",
      "modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.205\n",
      "modelì˜ Specificity ê°’ì€ 0.974\n",
      "modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.026\n",
      "modelì˜ precision ê°’ì€ 0.959\n",
      "modelì˜ f1_score ê°’ì€ 0.870\n",
      "modelì˜ G-mean ê°’ì€ 0.880\n",
      "modelì˜ accuracy ê°’ì€ 0.897\n",
      "\n",
      "modelì˜ recall ê°’ì€ 0.625\n",
      "modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.375\n",
      "modelì˜ Specificity ê°’ì€ 0.971\n",
      "modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.029\n",
      "modelì˜ precision ê°’ì€ 0.909\n",
      "modelì˜ f1_score ê°’ì€ 0.741\n",
      "modelì˜ G-mean ê°’ì€ 0.779\n",
      "modelì˜ accuracy ê°’ì€ 0.863\n",
      "0.02\n",
      "modelì˜ recall ê°’ì€ 0.830\n",
      "modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.170\n",
      "modelì˜ Specificity ê°’ì€ 0.974\n",
      "modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.026\n",
      "modelì˜ precision ê°’ì€ 0.961\n",
      "modelì˜ f1_score ê°’ì€ 0.890\n",
      "modelì˜ G-mean ê°’ì€ 0.899\n",
      "modelì˜ accuracy ê°’ì€ 0.911\n",
      "\n",
      "modelì˜ recall ê°’ì€ 0.625\n",
      "modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.375\n",
      "modelì˜ Specificity ê°’ì€ 0.971\n",
      "modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.029\n",
      "modelì˜ precision ê°’ì€ 0.909\n",
      "modelì˜ f1_score ê°’ì€ 0.741\n",
      "modelì˜ G-mean ê°’ì€ 0.779\n",
      "modelì˜ accuracy ê°’ì€ 0.863\n",
      "0.8\n",
      "modelì˜ recall ê°’ì€ 0.773\n",
      "modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.227\n",
      "modelì˜ Specificity ê°’ì€ 0.913\n",
      "modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.087\n",
      "modelì˜ precision ê°’ì€ 0.872\n",
      "modelì˜ f1_score ê°’ì€ 0.819\n",
      "modelì˜ G-mean ê°’ì€ 0.840\n",
      "modelì˜ accuracy ê°’ì€ 0.852\n",
      "\n",
      "modelì˜ recall ê°’ì€ 0.500\n",
      "modelì˜ 2ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.500\n",
      "modelì˜ Specificity ê°’ì€ 0.914\n",
      "modelì˜ 1ì¢… ì˜¤ë¥˜ í™•ë¥  ê°’ì€ 0.086\n",
      "modelì˜ precision ê°’ì€ 0.727\n",
      "modelì˜ f1_score ê°’ì€ 0.593\n",
      "modelì˜ G-mean ê°’ì€ 0.676\n",
      "modelì˜ accuracy ê°’ì€ 0.784\n"
     ]
    }
   ],
   "source": [
    "#ccp_alpha_list = list(np.arange(0.001,0.02,0.001))\n",
    "#ccp_alpha_list = list(np.arange(0.1,1,0.1))\n",
    "ccp_alpha_list = [0.002,0.02,0.8]\n",
    "\n",
    "train_scores =[]\n",
    "test_scores =[]\n",
    "for alpha in ccp_alpha_list: # ì‚¬ì „ì— ì •ì˜í•œ ë¦¬ìŠ¤íŠ¸ì˜ ê° ê°’ë§ˆë‹¤ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ìµœì ê°’ ë„ì¶œ\n",
    "    print(alpha)\n",
    "    clf = GradientBoostingClassifier(random_state=12,n_estimators = 500,\n",
    "                                     learning_rate = alpha\n",
    "                                     #max_depth=5,learning_rate = alpha\n",
    "                                    #,min_samples_leaf = 2,min_samples_split = 2\n",
    "                                    ,validation_fraction = 0.2\n",
    "                                     ,n_iter_no_change = 10\n",
    "                                     ,ccp_alpha = 0.013 \n",
    "                                   ) # ccp_alpha ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ì„œ ë¹„ìš©ë³µì¡ë„ê°€ ê°€ì¥ í° Subtreeë¡œ GBMëª¨ë¸ í•™ìŠµ\n",
    "    clf.fit(X_train,Y_train) # ì •ì˜í•œ GBM ëª¨ë¸ë¡œ í›ˆë ¨ë°ì´í„° í•™ìŠµ\n",
    "    \n",
    "    preds_train = clf.predict(X_train) # í›ˆë ¨ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ë¡œ yê°’ ì˜ˆì¸¡\n",
    "    preds = clf.predict(X_test) # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ yê°’ ì˜ˆì¸¡\n",
    "    \n",
    "    train_scores.append(f1_score(Y_train,preds_train)) # í›ˆë ¨ ì„±ëŠ¥ í‰ê°€\n",
    "    test_scores.append(f1_score(Y_test,preds)) # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€\n",
    "    print_all_reg(Y_train,preds_train) # í‰ê°€ì§€í‘œ ì¶œë ¥\n",
    "    print(\"\")\n",
    "    print_all_reg(Y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc1a5e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"cc\")\n",
    "ax.set_ylabel(\"f1 score\")\n",
    "#ax.set_xticklabels(ccp_alpha_list)\n",
    "\n",
    "#ax.set_title(\"ë‚˜ë¬´ ë³µì¡ë„ ì¦ê°€ì— ë”°ë¥¸ ì˜¤ë¶„ë¥˜ìœ¨ ê·¸ë˜í”„\")\n",
    "ax.plot(ccp_alpha_list,train_scores,  label=\"train data\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alpha_list,test_scores,  label=\"test data\", drawstyle=\"steps-post\")\n",
    "#ax.plot(ccp_alpha_list, pd.Series(train_scores).rolling(10,center =True).mean(),  label=\"train data\", drawstyle=\"steps-post\")\n",
    "#ax.plot(ccp_alpha_list, pd.Series(test_scores).rolling(10,center=True).mean(),  label=\"test data\", drawstyle=\"steps-post\")\n",
    "\n",
    "#ax.plot(ccp_alpha_list, train_scores, drawstyle=\"steps-post\")\n",
    "#ax.plot(ccp_alpha_list, test_scores, drawstyle=\"steps-post\")\n",
    "\n",
    "ax.legend()\n",
    "#plt.xlim(0.7)\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3104e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e81d91ba51e1bf9900dd7d036cbe3d31d033e3ae1051184964e8f8743fed6bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
